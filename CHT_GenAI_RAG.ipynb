import gradio as gr
import boto3
import json
import pprint
from botocore.client import Config

kb_id = "EALCUK2PXA"
title_string = []

# model_arn = f'arn:aws:bedrock:{region_id}::foundation-model/{model_id}'
model_Arn = "arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0"

bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})
bedrock_client = boto3.client('bedrock-runtime')
bedrock_agent_client = boto3.client("bedrock-agent-runtime", config=bedrock_config)

pp = pprint.PrettyPrinter(indent=2)


# -----------------  for dropdown start -----------------
options_1 = ['Claude 3 Haiku', 'Claude 3 Sonnet', 'Claude 3 Opus', 'Jurassic-2 Ultra v1', 'Jurassic-2 Ultra v2', 'Stability AI']
options_2 = {
    'Claude 3 Haiku': ['None', 'CHT-KB', '勞基法'],
    'Claude 3 Sonnet': ['None', 'CHT-KB', '勞基法'],
    'Claude 3 Opus': ['None', 'CHT-KB', '勞基法'],
    'Jurassic-2 Ultra v1': ['None', 'CHT-KB', '勞基法'],
    'Jurassic-2 Ultra v2': ['None', 'CHT-KB', '勞基法'],
    'Stability AI': ['None', 'CHT-KB', '勞基法'],
    }

with gr.Blocks() as dropdown:
    d1 = gr.Dropdown(choices=options_1, label="LLM")
    d2 = gr.Dropdown([], label="Knowledge Base")
    
    def update_second(first_val):
        d2 = gr.Dropdown(options_2[first_val], label="Knowledge Base")
        return d2 
    
    d1.input(update_second, d1, d2)

    outputs = gr.Textbox()

    def print_results(option_1, option_2):
        global title_string 
        title_string = f"{option_1} with :{option_2} Knowledge Base"
        return f"You selected:\n\nLLM: {option_1} \nKnowledge Base:{option_2}"
        
    d2.input(print_results, [d1, d2], outputs)

# -----------------  for dropdown end -----------------

# -----------------  for without knowledge base start-----------------


def generate_message(bedrock_runtime, model_id, system_prompt, messages, max_tokens):
    body = json.dumps(
       {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": max_tokens,
            "system": system_prompt,
            "messages": messages
       }
      )
    '''modelId = "anthropic.claude-3-sonnet-20240229-v1:0"'''
    string = ''

    response = bedrock_runtime.invoke_model_with_response_stream(body=body, modelId=model_id)
    for event in response.get("body"):
        chunk = json.loads(event["chunk"]["bytes"])
        if chunk['type'] == 'content_block_delta':
            if chunk['delta']['type'] == 'text_delta':
                print(chunk['delta']['text'], end="")
                string += chunk['delta']['text']

    assistant_message = {"role": "assistant", "content": string}
    messages.append(assistant_message)
    return (string)


def user_input_without_kb(imput_msg, history):
    bedrock_runtime = boto3.client(service_name="bedrock-runtime")
    model_id = "anthropic.claude-3-sonnet-20240229-v1:0"
    max_tokens = 1000
    system_prompt = "Respond as professional guy"
    user_message = {"role": "user", "content": imput_msg}
    messages.append(user_message)
    print(messages)
    response = generate_message(bedrock_runtime, model_id, system_prompt, messages, max_tokens)
    return response


messages = []

# -----------------  for without knowledge base end-----------------


def retrieveAndGenerate(input, kbId, modelArn):
    """
    https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent-runtime/client/retrieve_and_generate.html
    :param input:
    :param kbId:
    :return:
    """
    return bedrock_agent_client.retrieve_and_generate(
        input={
            'text': input
        },
        retrieveAndGenerateConfiguration={
            'type': 'KNOWLEDGE_BASE',
            'knowledgeBaseConfiguration': {
                'knowledgeBaseId': kbId,
                'modelArn': modelArn
            }
        }
    )
    return retrieveAndGenerateConfiguration


def user_input(imput_msg, history):
    query = imput_msg
    response = retrieveAndGenerate(query, kb_id, model_Arn)
    generated_text = response['output']['text']
    
    print(title_string)
    
    # print(json.dumps(response, indent=2, ensure_ascii=False))
    # pp.pprint(generated_text)
    
    '''
    citations = response["citations"]
    for citation in citations:
        retrievedReferences = citation["retrievedReferences"]
        for reference in retrievedReferences:
            contexts.append(reference["content"]["text"])
    '''
    # pp.pprint(contexts)
    return generated_text


contexts = []

# interface 1
app1 = dropdown
# interface 2
app2 = gr.ChatInterface(user_input,
                        title=title_string,
                        textbox=gr.Textbox(placeholder="Ask any questions here",
                                           container=False, scale=7),
                        description="詢問公司相關的福利",
                        theme="soft",
                        cache_examples=True,
                        retry_btn=None,
                        undo_btn="Delete Previous",
                        clear_btn="Clear",)

app3 = gr.ChatInterface(user_input_without_kb,
                        title="Amazon Bedrock with Claude3",
                        textbox=gr.Textbox(placeholder="Ask me a yes or no question",
                                           container=False, scale=7),
                        description="Ask Me any question",
                        theme="soft",
                        cache_examples=True,
                        retry_btn=None,
                        undo_btn="Delete Previous",
                        clear_btn="Clear",)


main = gr.TabbedInterface([app1, app2], ["Setting", "Chat"])
main.launch()